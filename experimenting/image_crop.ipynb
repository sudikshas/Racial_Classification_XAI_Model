{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import dlib\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import resnet_v2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = IM_HEIGHT = 224\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def detect_face(image_path, default_max_size=800,size = 300, padding = 0.25):\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('./dlib_mod/mmod_human_face_detector.dat')\n",
    "    sp = dlib.shape_predictor('./dlib_mod/shape_predictor_5_face_landmarks.dat')\n",
    "    base = 2000  # largest width and height\n",
    "\n",
    "    img = dlib.load_rgb_image(image_path)\n",
    "    old_height, old_width, _ = img.shape\n",
    "    old_height, old_width, _ = img.shape\n",
    "\n",
    "    if old_width > old_height:\n",
    "        new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)\n",
    "    else:\n",
    "        new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size\n",
    "    img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "    dets = cnn_face_detector(img, 1)\n",
    "    num_faces = len(dets)\n",
    "    if num_faces == 0:\n",
    "        print(\"Sorry, there were no faces found in '{}'\".format(image_path))\n",
    "        return\n",
    "    elif num_faces > 1:\n",
    "        print(\"Multiple face in '{}'. A random face will be returned\".format(image_path))\n",
    "    faces = dlib.full_object_detections()\n",
    "    for detection in dets:\n",
    "        rect = detection.rect\n",
    "        faces.append(sp(img, rect))\n",
    "    image = dlib.get_face_chips(img, faces, size=size, padding = padding)[0]\n",
    "\n",
    "    image = Image.fromarray(image, 'RGB')\n",
    "    image = image.resize((IM_WIDTH, IM_HEIGHT))\n",
    "\n",
    "    #image = np.array(image) / 255.0\n",
    "    ori_img = np.array(image)\n",
    "    processed_img = resnet_v2.preprocess_input(np.array(image))\n",
    "    processed_img = processed_img[None,:]\n",
    "    return ori_img, processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/teams/DSC180A_FA20_A00/a01explainableai/a01capstonegroup03/fairface_pad025/train/2450.jpg\"\n",
    "img_path_2 = \"IMG_3533.jpg\"#\"./test.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = detect_face(img_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'East Asian'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(img_path_2, model_path, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape == (1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(img_arr, model_path, mapping_path):\n",
    "    if img_arr.shape != (1, 224,224,3):\n",
    "        print(\"Wrong input size\")\n",
    "        return\n",
    "    else:\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        with open(mapping_path) as f:\n",
    "            mapping = json.load(f)\n",
    "        f.close()\n",
    "        mapping = {val:key for key, val in mapping.items()}\n",
    "        pred = model.predict(img_arr)\n",
    "        out = mapping[pred.argmax()]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "model_path = \"./models/race/race_v6.hdf5\"\n",
    "#model = keras.models.load_model(model_path)\n",
    "mapping = \"./mapping/race.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(b, model_path, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mapping) as f:\n",
    "    mappings = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_rev = {val:key for key, val in mappings.items()}\n",
    "map_rev[res.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
