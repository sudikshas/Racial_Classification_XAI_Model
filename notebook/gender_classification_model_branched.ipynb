{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/raw/'\n",
    "image_dir = os.path.join(data_path, 'fairface_pad025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/2.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/4.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/5.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file    age  gender        race  service_test\n",
       "0  train/1.jpg  50-59    Male  East Asian          True\n",
       "1  train/2.jpg  30-39  Female      Indian         False\n",
       "2  train/3.jpg    3-9  Female       Black         False\n",
       "3  train/4.jpg  20-29  Female      Indian          True\n",
       "4  train/5.jpg  20-29  Female      Indian          True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(os.path.join(data_path, 'fairface_label_train.csv'))\n",
    "\n",
    "val_csv = pd.read_csv(os.path.join(data_path, 'fairface_label_val.csv'))\n",
    "\n",
    "df = pd.concat([train_csv, val_csv])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ages(x):\n",
    "    if x == \"more than 70\":\n",
    "        return 70\n",
    "    else:\n",
    "        return np.mean([int(y) for y in x.split('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"age\"].apply(mean_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(os.path.join(image_dir, df.iloc[2, 0]))\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "\n",
    "dataset_dict = {\n",
    "    'race_id': {\n",
    "        0: 'White', \n",
    "        1: 'Black', \n",
    "        2: 'East Asian', \n",
    "        3: 'Indian', \n",
    "        4: 'Middle Eastern',\n",
    "        5: 'Latino_Hispanic',\n",
    "        6: 'Southeast Asian'\n",
    "    },\n",
    "    'gender_id': {\n",
    "        0: 'Male',\n",
    "        1: 'Female'\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\n",
    "dataset_dict['race_alias'] = dict((g, i) for i, g in dataset_dict['race_id'].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class FFFaceDataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the FFFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "\n",
    "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "        \n",
    "        # converts alias to id\n",
    "        self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\n",
    "        self.df['race_id'] = self.df['race'].map(lambda race: dataset_dict['race_alias'][race])\n",
    "\n",
    "        self.max_age = self.df['age'].max()\n",
    "        \n",
    "        return train_idx, valid_idx, test_idx\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # arrays to store our batched data\n",
    "        images, ages, races, genders = [], [], [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                person = self.df.iloc[idx]\n",
    "                \n",
    "                age = person['age']\n",
    "                race = person['race_id']\n",
    "                gender = person['gender_id']\n",
    "                file = os.path.join(image_dir, person['file'])\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                \n",
    "                ages.append(age / self.max_age)\n",
    "                races.append(to_categorical(race, len(dataset_dict['race_id'])))\n",
    "                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n",
    "                images.append(im)\n",
    "                \n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n",
    "                    images, ages, races, genders = [], [], [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "    def return_df(self):\n",
    "        return self.df\n",
    "                \n",
    "data_generator = FFFaceDataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = IM_HEIGHT = 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "class FFMultiOutputModel():\n",
    "    \"\"\"\n",
    "    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \n",
    "    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\n",
    "    on the make_default_hidden_layers method.\n",
    "    \"\"\"\n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "        \"\"\"\n",
    "        Used to generate a default set of hidden layers. The structure used in this network is defined as:\n",
    "        \n",
    "        Conv2D -> BatchNormalization -> Pooling -> Dropout\n",
    "        \"\"\"\n",
    "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_race_branch(self, inputs, num_races):\n",
    "        \"\"\"\n",
    "        Used to build the race branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_races)(x)\n",
    "        x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "\n",
    "        return x\n",
    "    def build_gender_branch(self, inputs, num_genders=2):\n",
    "        \"\"\"\n",
    "        Used to build the gender branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_genders)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_age_branch(self, inputs):   \n",
    "        \"\"\"\n",
    "        Used to build the age branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def assemble_full_model(self, width, height, num_races):\n",
    "        \"\"\"\n",
    "        Used to assemble our multi-output model CNN.\n",
    "        \"\"\"\n",
    "        input_shape = (height, width, 3)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        age_branch = self.build_age_branch(inputs)\n",
    "        race_branch = self.build_race_branch(inputs, num_races)\n",
    "        gender_branch = self.build_gender_branch(inputs)\n",
    "\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [age_branch, race_branch, gender_branch],\n",
    "                     name=\"face_net\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "model = FFMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "init_lr = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  'gender_output': 'binary_crossentropy'},\n",
    "              loss_weights={\n",
    "                  'gender_output': 0.1},\n",
    "              metrics={\n",
    "                  'gender_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# def get_available_gpus():\n",
    "#     local_device_protos = device_lib.list_local_devices()\n",
    "#     return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "# get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "valid_batch_size = 32\n",
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"../models/gender_checkpoint.hdf5\", monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "]\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>race_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1.jpg</td>\n",
       "      <td>54.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/2.jpg</td>\n",
       "      <td>34.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3.jpg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/4.jpg</td>\n",
       "      <td>24.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/5.jpg</td>\n",
       "      <td>24.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>val/10950.jpg</td>\n",
       "      <td>34.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>val/10951.jpg</td>\n",
       "      <td>54.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>val/10952.jpg</td>\n",
       "      <td>64.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>val/10953.jpg</td>\n",
       "      <td>24.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>val/10954.jpg</td>\n",
       "      <td>44.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97698 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file   age  gender             race  service_test  gender_id  \\\n",
       "0        train/1.jpg  54.5    Male       East Asian          True          0   \n",
       "1        train/2.jpg  34.5  Female           Indian         False          1   \n",
       "2        train/3.jpg   6.0  Female            Black         False          1   \n",
       "3        train/4.jpg  24.5  Female           Indian          True          1   \n",
       "4        train/5.jpg  24.5  Female           Indian          True          1   \n",
       "...              ...   ...     ...              ...           ...        ...   \n",
       "10949  val/10950.jpg  34.5    Male            White          True          0   \n",
       "10950  val/10951.jpg  54.5    Male            White         False          0   \n",
       "10951  val/10952.jpg  64.5    Male  Latino_Hispanic         False          0   \n",
       "10952  val/10953.jpg  24.5  Female       East Asian         False          1   \n",
       "10953  val/10954.jpg  44.5    Male  Latino_Hispanic          True          0   \n",
       "\n",
       "       race_id  \n",
       "0            2  \n",
       "1            3  \n",
       "2            1  \n",
       "3            3  \n",
       "4            3  \n",
       "...        ...  \n",
       "10949        0  \n",
       "10950        0  \n",
       "10951        5  \n",
       "10952        2  \n",
       "10953        5  \n",
       "\n",
       "[97698 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator.return_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object FFFaceDataGenerator.generate_images at 0x7fad201c9950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
